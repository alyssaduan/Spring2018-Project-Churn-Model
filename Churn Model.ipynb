{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHURN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we consider the study case of churn problem. Namely, we want to predict whether a customer will churn to another company when his/her contract expires based on a data set consisting of some information features. Basically, we seperate our whole data into two parts: the traning data set and the test data set.\n",
    "\n",
    "Firstly, we use our training data set to check the data information and then analyze the correlation between each feature by using Pandas. After dealing with the training data set, we set the features to be our $X$ and the LEAVE data to be our $Y$. Using these to fit our model. \n",
    "\n",
    "In particular, we will try two models: Logistic Regression and SVM. We want to compare them and see which one is better for our data so that we can get higher accuracy when we estimate our test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deal With the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will import the training dataset, analyze the dataset and perpare the data in order to fit the model later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Import Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import pandas to read our csv data files and name our train data set as \"df_train\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, decomposition,\\\n",
    "    linear_model, pipeline, metrics\n",
    "    \n",
    "DATA_DIR = \"../data/\"\n",
    "df_train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 12 columns):\n",
      "COLLEGE                        18000 non-null object\n",
      "INCOME                         18000 non-null int64\n",
      "OVERAGE                        18000 non-null int64\n",
      "LEFTOVER                       18000 non-null int64\n",
      "HOUSE                          18000 non-null int64\n",
      "HANDSET_PRICE                  18000 non-null int64\n",
      "OVER_15MINS_CALLS_PER_MONTH    18000 non-null int64\n",
      "AVERAGE_CALL_DURATION          18000 non-null int64\n",
      "REPORTED_SATISFACTION          18000 non-null object\n",
      "REPORTED_USAGE_LEVEL           18000 non-null object\n",
      "CONSIDERING_CHANGE_OF_PLAN     18000 non-null object\n",
      "LEAVE                          18000 non-null int64\n",
      "dtypes: int64(8), object(4)\n",
      "memory usage: 1.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>OVERAGE</th>\n",
       "      <th>LEFTOVER</th>\n",
       "      <th>HOUSE</th>\n",
       "      <th>HANDSET_PRICE</th>\n",
       "      <th>OVER_15MINS_CALLS_PER_MONTH</th>\n",
       "      <th>AVERAGE_CALL_DURATION</th>\n",
       "      <th>REPORTED_SATISFACTION</th>\n",
       "      <th>REPORTED_USAGE_LEVEL</th>\n",
       "      <th>CONSIDERING_CHANGE_OF_PLAN</th>\n",
       "      <th>LEAVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zero</td>\n",
       "      <td>31953</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>313378</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>unsat</td>\n",
       "      <td>little</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>36147</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>800586</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>unsat</td>\n",
       "      <td>little</td>\n",
       "      <td>considering</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>27273</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>305049</td>\n",
       "      <td>201</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>unsat</td>\n",
       "      <td>very_little</td>\n",
       "      <td>perhaps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zero</td>\n",
       "      <td>120070</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>788235</td>\n",
       "      <td>780</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>unsat</td>\n",
       "      <td>very_high</td>\n",
       "      <td>considering</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>29215</td>\n",
       "      <td>208</td>\n",
       "      <td>85</td>\n",
       "      <td>224784</td>\n",
       "      <td>241</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>very_unsat</td>\n",
       "      <td>little</td>\n",
       "      <td>never_thought</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  COLLEGE  INCOME  OVERAGE  LEFTOVER   HOUSE  HANDSET_PRICE  \\\n",
       "0    zero   31953        0         6  313378            161   \n",
       "1     one   36147        0        13  800586            244   \n",
       "2     one   27273      230         0  305049            201   \n",
       "3    zero  120070       38        33  788235            780   \n",
       "4     one   29215      208        85  224784            241   \n",
       "\n",
       "   OVER_15MINS_CALLS_PER_MONTH  AVERAGE_CALL_DURATION REPORTED_SATISFACTION  \\\n",
       "0                            0                      4                 unsat   \n",
       "1                            0                      6                 unsat   \n",
       "2                           16                     15                 unsat   \n",
       "3                            3                      2                 unsat   \n",
       "4                           21                      1            very_unsat   \n",
       "\n",
       "  REPORTED_USAGE_LEVEL CONSIDERING_CHANGE_OF_PLAN  LEAVE  \n",
       "0               little                         no      1  \n",
       "1               little                considering      1  \n",
       "2          very_little                    perhaps      1  \n",
       "3            very_high                considering      0  \n",
       "4               little              never_thought      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By printing out the information and the headings of our train data set, we found that there are some objects instead of integers. Then we want to transfer the object into the catogory data as below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Catogorize Data by Using Catagory Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking our data, we found that some of our data is represented as characters, we want to convert these into numbers. Thus, we replace the COLLEGE, REPORTED_SATISFACTION, REPORTED_USAGE_LEVEL and CONSIDERING_CHANGE_OF_PLAN colunmns into catagory numbers. Then print out the head of our data again to double check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>OVERAGE</th>\n",
       "      <th>LEFTOVER</th>\n",
       "      <th>HOUSE</th>\n",
       "      <th>HANDSET_PRICE</th>\n",
       "      <th>OVER_15MINS_CALLS_PER_MONTH</th>\n",
       "      <th>AVERAGE_CALL_DURATION</th>\n",
       "      <th>REPORTED_SATISFACTION</th>\n",
       "      <th>REPORTED_USAGE_LEVEL</th>\n",
       "      <th>CONSIDERING_CHANGE_OF_PLAN</th>\n",
       "      <th>LEAVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31953</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>313378</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>36147</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>800586</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>27273</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>305049</td>\n",
       "      <td>201</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>120070</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>788235</td>\n",
       "      <td>780</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>29215</td>\n",
       "      <td>208</td>\n",
       "      <td>85</td>\n",
       "      <td>224784</td>\n",
       "      <td>241</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COLLEGE  INCOME  OVERAGE  LEFTOVER   HOUSE  HANDSET_PRICE  \\\n",
       "0        0   31953        0         6  313378            161   \n",
       "1        1   36147        0        13  800586            244   \n",
       "2        1   27273      230         0  305049            201   \n",
       "3        0  120070       38        33  788235            780   \n",
       "4        1   29215      208        85  224784            241   \n",
       "\n",
       "   OVER_15MINS_CALLS_PER_MONTH  AVERAGE_CALL_DURATION  REPORTED_SATISFACTION  \\\n",
       "0                            0                      4                   -0.5   \n",
       "1                            0                      6                   -0.5   \n",
       "2                           16                     15                   -0.5   \n",
       "3                            3                      2                   -0.5   \n",
       "4                           21                      1                   -1.0   \n",
       "\n",
       "   REPORTED_USAGE_LEVEL  CONSIDERING_CHANGE_OF_PLAN  LEAVE  \n",
       "0                  -0.5                        -0.5      1  \n",
       "1                  -0.5                         0.0      1  \n",
       "2                  -1.0                         0.5      1  \n",
       "3                   1.0                         0.0      0  \n",
       "4                  -0.5                        -1.0      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete the negative fraud data from OVERAGE \n",
    "df_train = df_train[df_train.OVERAGE >= 0]\n",
    "\n",
    "df_train['COLLEGE'] = df_train['COLLEGE'].replace({\"one\": 1, \"zero\": 0})\n",
    "df_train['REPORTED_SATISFACTION'] = df_train['REPORTED_SATISFACTION'].replace({\"unsat\": -0.5, \"very_unsat\": -1,\"very_sat\":1,\"avg\":0,\"sat\":0.5})\n",
    "df_train['REPORTED_USAGE_LEVEL'] = df_train['REPORTED_USAGE_LEVEL'].replace({\"little\": -0.5, \"very_little\": -1,\"very_high\":1,\"avg\":0,\"high\":0.5})\n",
    "df_train['CONSIDERING_CHANGE_OF_PLAN'] = df_train['CONSIDERING_CHANGE_OF_PLAN'].replace({\"no\": -0.5, \"considering\": 0,\"perhaps\":0.5,\"never_thought\":-1,\"actively_looking_into_it\":1})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Analyze the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the pandas convenient one-line method $corr()$ to calculate correlation between data frame columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLLEGE : -0.015381265908933713\n",
      "INCOME : -0.09785130295420438\n",
      "OVERAGE : -0.23201797602264684\n",
      "LEFTOVER : -0.0602332121529971\n",
      "HOUSE : 0.21080821161190402\n",
      "HANDSET_PRICE : -0.09194575623331838\n",
      "OVER_15MINS_CALLS_PER_MONTH : -0.1984867009311266\n",
      "AVERAGE_CALL_DURATION : 0.006794284597085972\n",
      "REPORTED_SATISFACTION : 0.01035083723080867\n",
      "REPORTED_USAGE_LEVEL : 0.0021172996871939693\n",
      "CONSIDERING_CHANGE_OF_PLAN : -0.0033917653657393435\n"
     ]
    }
   ],
   "source": [
    "features = list(df_train.columns[:11])\n",
    "for i in features[0:11]:\n",
    "    corr= df_train[i].corr(df_train['LEAVE'])\n",
    "    print(i,':',corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation calculation above, we noticed that all coeffiencents do  not have very strong connection with LEAVE. However, we still can find that the OVERAGE and HOUSE have relative strong correlation with LEAVE. Also, REPORTED_USAGE_LEVEL and CONSIDERING_CHANGE_OF_PLAN have relatively weak correlation with LEAVE. \n",
    "\n",
    "However, since all coefficients do not have obvious correlation, we will not delete any features in our dataset. Instead, we will separate our dataset into three parts and then combine all of them into $X$ as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Use StandardScaler to Fit Data and Set as X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first separate our data into three parts, the catagory data set, the Income and House set, others. Since the Income and House data numbers are kind of larger than others, we separate it into our second_part_train data. Then we use numpy hstack to stack arrays in sequence horizontally and named the whole thing to be our \"x_train\". Finally, we use standardScaler to scale our train data set. As shown below, we print out the data before and after applying standardscaler to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before [[ 0.00000000e+00 -5.00000000e-01 -5.00000000e-01 -5.00000000e-01\n",
      "   0.00000000e+00  6.00000000e+00  1.61000000e+02  0.00000000e+00\n",
      "   4.00000000e+00  1.78754021e+02  5.59801751e+02]\n",
      " [ 1.00000000e+00 -5.00000000e-01 -5.00000000e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.30000000e+01  2.44000000e+02  0.00000000e+00\n",
      "   6.00000000e+00  1.90123644e+02  8.94754715e+02]\n",
      " [ 1.00000000e+00 -5.00000000e-01 -1.00000000e+00  5.00000000e-01\n",
      "   2.30000000e+02  0.00000000e+00  2.01000000e+02  1.60000000e+01\n",
      "   1.50000000e+01  1.65145390e+02  5.52312412e+02]]\n",
      "after [[-1.00685722 -0.34519328 -0.53951473 -0.89800055 -1.00052508 -0.66564605\n",
      "  -1.07251763 -0.89581065 -0.45616125 -1.24509578 -0.64948249]\n",
      " [ 0.99318948 -0.34519328 -0.53951473 -0.11513162 -1.00052508 -0.40468461\n",
      "  -0.68467971 -0.89581065 -0.00208132 -1.09511029  1.19518626]\n",
      " [ 0.99318948 -0.34519328 -1.20037806  0.66773731  1.6730904  -0.88932728\n",
      "  -0.88560779  0.89792838  2.04127839 -1.42461775 -0.69072814]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SuperBubble\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n",
      "C:\\Users\\SuperBubble\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_train.head()\n",
    "\n",
    "dont_change_train = df_train[['COLLEGE','REPORTED_SATISFACTION','REPORTED_USAGE_LEVEL',\n",
    "                         'CONSIDERING_CHANGE_OF_PLAN']]\n",
    "\n",
    "frist_part_train = df_train[['OVERAGE','LEFTOVER','HANDSET_PRICE','OVER_15MINS_CALLS_PER_MONTH',\n",
    "                          'AVERAGE_CALL_DURATION']].as_matrix()\n",
    "\n",
    "second_part_train = np.sqrt(df_train[['INCOME','HOUSE']]).as_matrix()\n",
    "\n",
    "x_train = np.hstack((dont_change_train,frist_part_train,second_part_train))\n",
    "standardScaler = preprocessing.StandardScaler()\n",
    "print(\"before\",x_train[:3,:])\n",
    "\n",
    "standardScaler.fit(x_train)\n",
    "x_train = standardScaler.transform(x_train)\n",
    "print(\"after\",x_train[:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Set the LEAVE column as Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print out the shape and first 10 elements of our LEAVE data to check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17999,)\n",
      "[1 1 1 0 1 1 1 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SuperBubble\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train['LEAVE'].as_matrix()\n",
    "print(y_train.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deal with Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we do the same thing as above to prepare our test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import, Catogory and Normalize the Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using similar idea, we import our test data, catogorize the object features and normalize our test data in order to fit our model to get the target prediction \"LEAVE\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before normalize [[ 1.00000000e+00 -1.00000000e+00 -1.00000000e+00  1.00000000e+00\n",
      "   2.02000000e+02  0.00000000e+00  5.62000000e+02  2.90000000e+01\n",
      "   1.30000000e+01  3.77896811e+02  5.14170205e+02]\n",
      " [ 0.00000000e+00 -5.00000000e-01  5.00000000e-01  1.00000000e+00\n",
      "   6.60000000e+01  4.50000000e+01  1.90000000e+02  3.00000000e+00\n",
      "   2.00000000e+00  2.03794014e+02  7.86884998e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.00000000e+00 -5.00000000e-01\n",
      "   1.91000000e+02  6.10000000e+01  3.55000000e+02  2.10000000e+01\n",
      "   1.00000000e+00  2.27857412e+02  9.93150542e+02]]\n",
      "after normalize [[ 0.99318948 -0.95835166 -1.20037806  1.45060623  1.34760678 -0.88932728\n",
      "   0.80125355  2.35534134  1.58719845  1.38195078 -0.90078669]\n",
      " [-1.00685722 -0.34519328  0.78221191  1.45060623 -0.23331368  0.78828195\n",
      "  -0.937008   -0.55948458 -0.91024118 -0.91477387  0.60112107]\n",
      " [-1.00685722  0.2679651  -1.20037806 -0.89800055  1.21973821  1.38476523\n",
      "  -0.16600489  1.45847183 -1.13728115 -0.59733498  1.7370764 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SuperBubble\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\SuperBubble\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "## import data\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test = df_test[df_test.OVERAGE >= 0]\n",
    "\n",
    "## catogory data\n",
    "df_test['COLLEGE'] = df_test['COLLEGE'].replace({\"one\": 1, \"zero\": 0})\n",
    "df_test['REPORTED_SATISFACTION'] = df_test['REPORTED_SATISFACTION'].replace({\"unsat\": -0.5, \"very_unsat\": -1,\"very_sat\":1,\"avg\":0,\"sat\":0.5})\n",
    "df_test['REPORTED_USAGE_LEVEL'] = df_test['REPORTED_USAGE_LEVEL'].replace({\"little\": -0.5, \"very_little\": -1,\"very_high\":1,\"avg\":0,\"high\":0.5})\n",
    "df_test['CONSIDERING_CHANGE_OF_PLAN'] = df_test['CONSIDERING_CHANGE_OF_PLAN'].replace({\"no\": -0.5, \"considering\": 0,\"perhaps\":0.5,\"never_thought\":-1,\"actively_looking_into_it\":1})\n",
    "df_test.head()\n",
    "\n",
    "## normalize test data set\n",
    "dont_change_test = df_test[['COLLEGE','REPORTED_SATISFACTION','REPORTED_USAGE_LEVEL',\n",
    "                          'CONSIDERING_CHANGE_OF_PLAN']]\n",
    "\n",
    "frist_part_test = df_test[['OVERAGE','LEFTOVER','HANDSET_PRICE','OVER_15MINS_CALLS_PER_MONTH',\n",
    "                          'AVERAGE_CALL_DURATION']].as_matrix()\n",
    "second_part_test = np.sqrt(df_test[['INCOME','HOUSE']]).as_matrix()\n",
    "\n",
    "x_test = np.hstack((dont_change_test,frist_part_test,second_part_test))\n",
    "\n",
    "print(\"before normalize\",x_test[:3,:])\n",
    "x_test = standardScaler.transform(x_test)\n",
    "print(\"after normalize\",x_test[:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit Model Using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparing the data, we first try to use the LogisticRegression. The score of the model is printed as below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6392941176470588 0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "#logistic\n",
    "model = linear_model.LogisticRegressionCV(cv=10,verbose=5)\n",
    "model.fit(x_train[:17000,:],y_train[:17000])\n",
    "train_loss= model.score(x_train[:17000,:],y_train[:17000])\n",
    "val_loss = model.score(x_train[:1000,:],y_train[:1000])\n",
    "print(train_loss,val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the predict score we get is 0.6392941176470588, which is not very good. Then we try to use a method called polynomial features for our x_train data to check if we can increase the accuracy. Basically, we generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to a specific degree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17999, 78)\n",
      "(2000, 78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6694705882352942\n",
      "0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.1s finished\n"
     ]
    }
   ],
   "source": [
    "polyFeaturizer = preprocessing.PolynomialFeatures(2)\n",
    "polyFeaturizer.fit(x_train)\n",
    "x_train_poly = polyFeaturizer.transform(x_train)\n",
    "print(x_train_poly.shape)\n",
    "\n",
    "x_test_poly = polyFeaturizer.transform(x_test)\n",
    "print(x_test_poly.shape)\n",
    "\n",
    "#logistic\n",
    "scaler2 = preprocessing.StandardScaler()\n",
    "x_train_poly_normalized = scaler2.fit_transform(x_train_poly)\n",
    "x_test_poly_normalized = scaler2.transform(x_test_poly)\n",
    "model = linear_model.LogisticRegressionCV(cv=10,verbose=5)\n",
    "model.fit(x_train_poly_normalized[:17000,:],y_train[:17000])\n",
    "print(model.score(x_train_poly_normalized[:17000,:],y_train[:17000]))\n",
    "print(model.score(x_train_poly_normalized[:1000,:],y_train[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the accurancy increases to 0.69 for a polynomial of degree less than 2. Then we tried a ploynomial with degree 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17999, 364)\n",
      "(2000, 364)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6888235294117647\n",
      "0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   20.2s finished\n"
     ]
    }
   ],
   "source": [
    "#logistic\n",
    "polyFeaturizer = preprocessing.PolynomialFeatures(3)\n",
    "polyFeaturizer.fit(x_train)\n",
    "x_train_poly = polyFeaturizer.transform(x_train)\n",
    "print(x_train_poly.shape)\n",
    "\n",
    "x_test_poly = polyFeaturizer.transform(x_test)\n",
    "print(x_test_poly.shape)\n",
    "\n",
    "scaler2 = preprocessing.StandardScaler()\n",
    "x_train_poly_normalized = scaler2.fit_transform(x_train_poly)\n",
    "x_test_poly_normalized = scaler2.transform(x_test_poly)\n",
    "model = linear_model.LogisticRegressionCV(cv=10,verbose=5)\n",
    "model.fit(x_train_poly_normalized[:17000,:],y_train[:17000])\n",
    "print(model.score(x_train_poly_normalized[:17000,:],y_train[:17000]))\n",
    "print(model.score(x_train_poly_normalized[:1000,:],y_train[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By fitting model using Logistic Regression, we can conclude that the logistic regression does not work well for our data and higer degree of polynomials may cause the overfitting problem which is not general and good enough for the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17999,)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_train_poly_normalized)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit Model Using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying the Logistic Regression, we would like to try the SVM regression as below to check if this model can have a higher accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6984705882352941 0.698\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(x_train[:17000,:],y_train[:17000])\n",
    "train_loss= model.score(x_train[:17000,:],y_train[:17000])\n",
    "val_loss = model.score(x_train[:1000,:],y_train[:1000])\n",
    "print(train_loss,val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the SVM model works better than the Logistic Regression model. The accurancy approximates to 0.69, which is not bad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we save our prediction LEAVE data into the \"prediation\" array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write Prediction Into File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a \"write_pred_to_file\" function as below and write our predicitons above into the \"test_submit.csv\" file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pred_to_file(y_pred,filename):\n",
    "    fpt = open(filename,\"w\")\n",
    "    fpt.write(\"ID,LEAVE\\n\")\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        fpt.write(str(i)+\",\"+str(int(y_pred[i]))+\"\\n\")\n",
    "write_pred_to_file(predictions,\"test_submit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above analysis, we can conclude that for our data set, the SVM has better prediction than the Logistic Regression. In addition, we cannot use polynomial with relatively high degree to increase our training data accurancy, since it will cause the overfitting problem and lose the general and accurancy for test data.\n",
    "\n",
    "In the future, we will try to use confusion matrix to analyze the classification. Also, we would like to use the Tableau to virtualize the dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
